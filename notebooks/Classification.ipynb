{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to train classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "import lofo\n",
    "import torch\n",
    "import pickle\n",
    "import optuna\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "from inference.main import k_fold_inf\n",
    "from numerize.numerize import numerize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pandarallel.initialize(progress_bar=False, use_memory_fs=False)\n",
    "pd.options.display.max_columns = 500\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.features import *\n",
    "from data.preparation import *\n",
    "from data.post_processing import *\n",
    "\n",
    "from utils.logger import prepare_log_folder, create_logger, save_config\n",
    "from utils.metrics import *\n",
    "\n",
    "from model_zoo.xgb import objective_xgb, lofo_xgb\n",
    "from model_zoo.catboost import objective_catboost\n",
    "from training.main_boosting import k_fold\n",
    "from utils.plot import *\n",
    "\n",
    "from matching import get_CV, load_cleaned_data\n",
    "from pp import get_improved_CV\n",
    "from dtypes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVEL = 1\n",
    "\n",
    "N_FOLDS = 10  # 10 if LEVEL == 2 else 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH + \"train.csv\")[[\"id\", \"point_of_interest\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'../output/folds_{N_FOLDS}.csv'\n",
    "\n",
    "if os.path.exists(path):\n",
    "    df_split = pd.read_csv(path)\n",
    "else:\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "\n",
    "    gkf = GroupKFold(n_splits=N_FOLDS)\n",
    "    splits = list(gkf.split(df[\"id\"], groups=df['point_of_interest']))\n",
    "\n",
    "\n",
    "    df_split = df[[\"id\", \"point_of_interest\"]].copy()\n",
    "    df_split['fold'] = -1\n",
    "\n",
    "    for i, (_, val_idx) in enumerate(splits):\n",
    "        df_split.loc[val_idx, 'fold'] = i\n",
    "\n",
    "    df_split.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LEVEL == 1:\n",
    "    df_p = pd.read_csv(OUT_PATH + f\"features_train_1.csv\", dtype=DTYPES_1)\n",
    "    THRESHOLD = 0\n",
    "else:\n",
    "    THRESHOLD = 0.0075\n",
    "    df_p = pd.read_csv(OUT_PATH + f\"features_train_2_{THRESHOLD}.csv\", dtype=DTYPES_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = list(df_p.columns[2:])\n",
    "\n",
    "FEATURES = [\n",
    "    f for f in FEATURES if f not in ['point_of_interest_1', 'fold_1', 'point_of_interest_2', 'fold_2', 'match']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"fold_1\" not in df_p.columns:\n",
    "    df_p = df_p.merge(df_split, left_on=\"id_1\", right_on=\"id\", how=\"left\").drop('id', axis=1)\n",
    "    df_p = df_p.merge(df_split, left_on=\"id_2\", right_on=\"id\", how=\"left\", suffixes=('_1', '_2')).drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"match\" not in df_p.columns:\n",
    "    df_p['match'] = (df_p['point_of_interest_1'] == df_p['point_of_interest_2']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df_p.sort_values(['id_1', 'id_2']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LEVEL == 1:\n",
    "    PARAMS = {\n",
    "        \"xgb\":\n",
    "        {\n",
    "            \"learning_rate\": 0.05,\n",
    "            'max_depth': 10,\n",
    "            'min_child_weight': 0.01,\n",
    "            'reg_alpha': 0.01,\n",
    "            'reg_lambda': 0.1,\n",
    "            \"colsample_bytree\": 0.95,\n",
    "            \"subsample\": 0.75,\n",
    "        },    \n",
    "        \"catboost\":\n",
    "        {\n",
    "            \"learning_rate\": 0.1,\n",
    "            'depth': 12,\n",
    "            \"l2_leaf_reg\": 0.1,\n",
    "            \"min_data_in_leaf\": 2000,\n",
    "#             \"subsample\": 0.75,\n",
    "#             \"bootstrap_type\": \"Poisson\",\n",
    "        },\n",
    "        \"lgbm\": {\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 500,\n",
    "            \"reg_alpha\": 1,\n",
    "            \"reg_lambda\": 10,\n",
    "            \"min_child_samples\": 1000,\n",
    "            \"min_split_gain\": 0.01,\n",
    "            \"min_child_weight\": 0.01,\n",
    "            \"path_smooth\": 0.1,\n",
    "#             \"min_data_in_bin\": 320,\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    PARAMS = {\n",
    "        \"xgb\":\n",
    "        {\n",
    "            \"learning_rate\": 0.05,\n",
    "            'max_depth': 15,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'reg_alpha': 1,\n",
    "            'reg_lambda': 10,\n",
    "            \"min_child_weight\": 0.1,\n",
    "            \"gamma\": 0.1,\n",
    "        },\n",
    "        \"catboost\":\n",
    "            {\n",
    "            'depth': 12,\n",
    "            \"l2_leaf_reg\": 0.1,\n",
    "            \"min_data_in_leaf\": 2000,\n",
    "#             'reg_lambda': 0.1,\n",
    "#             \"model_size_reg\": 0.5,\n",
    "#             \"border_count\": 256,\n",
    "            },\n",
    "        \"lgbm\": {\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 511,\n",
    "            \"colsample_bytree\": 0.5,\n",
    "            \"reg_alpha\": 1,\n",
    "            \"reg_lambda\": 70,\n",
    "            \"min_child_samples\": 2000,  # MODIF  # 2000\n",
    "            \"min_split_gain\": 0.02,\n",
    "            \"min_child_weight\": 0.03,\n",
    "            \"path_smooth\": 0.2,\n",
    "#             \"min_data_in_bin\": 32,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZE = False\n",
    "TRAIN = True\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LEVEL == 1:\n",
    "    LOW_IMP = []\n",
    "else:\n",
    "    LOW_IMP = [\n",
    "        'url_cc_max', 'url_cc_min', 'address_any_nan', 'address_both_nan', 'city_any_nan', 'zip_both_nan', 'phone_both_nan'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    level = LEVEL\n",
    "    threshold = THRESHOLD\n",
    "\n",
    "    split = \"kf\" # if LEVEL == 1 else \"kf\"\n",
    "    n_folds = N_FOLDS\n",
    "\n",
    "    features = FEATURES\n",
    "    features = [f for f in FEATURES if f not in LOW_IMP]\n",
    "\n",
    "    cat_features = ['country', 'cat2a', 'cat2b', \"langs\", \"cat_simpl\", \"name_num\", \"address_num\"]\n",
    "    cat_features = [c for c in cat_features if c in FEATURES]\n",
    "\n",
    "    target = \"match\"\n",
    "    model = \"lgbm\"\n",
    "    params = PARAMS[model]\n",
    "    selected_folds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    \n",
    "    use_es = split == \"gkf\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(Config.cat_features):\n",
    "    df_p[Config.cat_features] = df_p[Config.cat_features].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if TRAIN:\n",
    "    log_folder = None\n",
    "    if not DEBUG:\n",
    "        log_folder = prepare_log_folder(LOG_PATH + f\"lvl_{LEVEL}/\")\n",
    "        print(f'Logging results to {log_folder}')\n",
    "        save_config(Config, log_folder + 'config')\n",
    "        create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "    pred_oof, models, ft_imp = k_fold(df_p, Config, log_folder=log_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY YOUR OWN EXPS\n",
    "if LEVEL == 1:\n",
    "    EXP_FOLDER = LOG_PATH + \"lvl_1/\" + \"2022-07-02/2/\"\n",
    "else:\n",
    "    EXP_FOLDER = LOG_PATH + \"lvl_2/\" + \"2022-07-03/3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAIN:\n",
    "    pred_oof = np.load(EXP_FOLDER + \"pred_oof.npy\")\n",
    "    ft_imp = pd.read_csv(EXP_FOLDER + \"ft_imp.csv\").set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_p[Config.target].values if isinstance(df_p, pd.DataFrame) else df_p[Config.target].get()\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    pred_oof > 0.5,\n",
    "    y,\n",
    "    display_labels=['No Match', 'Match'],\n",
    "#     normalize=\"pred\"\n",
    ")\n",
    "\n",
    "plt.title(f\"AUC = {roc_auc_score(y, pred_oof) :.4f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"m_true\" not in df.columns:\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values(by=[\"point_of_interest\", \"id\"]).reset_index(drop=True)\n",
    "\n",
    "    id_all = np.array(df[\"id\"])\n",
    "    poi_all = np.array(df[\"point_of_interest\"])\n",
    "    poi0 = poi_all[0]\n",
    "    id0 = id_all[0]\n",
    "\n",
    "    di_poi = {}\n",
    "    for i in range(1, df.shape[0]):\n",
    "        if poi_all[i] == poi0:\n",
    "            id0 = str(id0) + \" \" + str(id_all[i])\n",
    "        else:\n",
    "            di_poi[poi0] = str(id0) + \" \"  # need to have trailing space in m_true\n",
    "            poi0 = poi_all[i]\n",
    "            id0 = id_all[i]\n",
    "\n",
    "    di_poi[poi0] = str(id0) + \" \"  # need to have trailing space in m_true\n",
    "    df[\"m_true\"] = df[\"point_of_interest\"].map(di_poi)\n",
    "\n",
    "    df = df.sort_values(by=\"index\").reset_index(\n",
    "        drop=True\n",
    "    )  # sort back to original order\n",
    "    df.drop(\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_improved_CV(df_p, pred_oof, df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check several cut levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if LEVEL == 1:\n",
    "    df_p[Config.target] = y\n",
    "\n",
    "    for thresh in [.0025, .005, .0075]:\n",
    "        print(f'\\nRemoving pairs with p < {thresh} : ')\n",
    "        df_cut = df_p.loc[pred_oof > thresh].reset_index()\n",
    "        y_cut = df_cut[Config.target].values\n",
    "\n",
    "        try:\n",
    "            print(f\"- Number of candidates : {numerize(len(y_cut))}\")\n",
    "        except NameError:\n",
    "            print(f\"- Number of candidates : {len(y_cut)}\")\n",
    "        print(f\"- Proportion of positive candidates: {y_cut.mean() * 100:.2f}%\")\n",
    "\n",
    "        get_CV(None, None, y_cut, y_cut, df.copy(), df_cut.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if LEVEL == 1:\n",
    "    THRESHOLD = 0.0075\n",
    "\n",
    "    df_p_r = df_p[pred_oof > THRESHOLD].reset_index(drop=True)\n",
    "    df_p_r.to_csv(OUT_PATH + f\"features_train_1_filtered_{THRESHOLD}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_importances(ft_imp)\n",
    "# plt.xscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
