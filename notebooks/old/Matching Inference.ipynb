{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to infer pairs from NN models\n",
    "**TODO**:\n",
    "- Intersection\n",
    "- Filter using dist_nn < th_1 and dist_pos < th_2\n",
    "- https://github.com/facebookresearch/faiss\n",
    "- https://www.kaggle.com/c/shopee-product-matching/discussion/238022\n",
    "- https://www.kaggle.com/c/shopee-product-matching/discussion/238515\n",
    "- https://www.kaggle.com/c/shopee-product-matching/discussion/238136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from numerize.numerize import numerize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.preparation import prepare_train_data, prepare_triplet_data\n",
    "from data.dataset import SingleDataset\n",
    "from data.tokenization import get_tokenizer\n",
    "\n",
    "from model_zoo.models import SingleTransformer\n",
    "\n",
    "from utils.logger import Config\n",
    "from utils.torch import load_model_weights\n",
    "from utils.metrics import *\n",
    "\n",
    "from inference.predict import predict\n",
    "from inference.knn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = prepare_train_data(root=DATA_PATH)\n",
    "# build_gt(df.reset_index(), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = pd.read_csv(DATA_PATH + \"folds_2.csv\")[['id', 'fold']]\n",
    "df = df.merge(folds, how=\"left\", on=\"id\").set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[df['fold'] == FOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_matches = json.load(open(DATA_PATH + \"gt.json\", 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP_FOLDER = LOG_PATH + \"2022-05-18/2/\"\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-18/3/\"  # 10 ep\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-19/0/\"  # 2 ep, triplets_v2\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-19/1/\"  # 1 ep, triplets_v2, d=64\n",
    "\n",
    "EXP_FOLDER = LOG_PATH + \"2022-05-19/2/\"  # 1 ep, d=256\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-19/4/\"  # 1 ep, d=256, large\n",
    "\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-20/0/\"  # 1 ep, d=256, triplets_v2\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-20/1/\"  # roberta-large\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-20/2/\"  # base + url\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-20/3/\"  # large + no address\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-22/0/\"  # 1 ep, d=256, large lower\n",
    "# EXP_FOLDER = LOG_PATH + \"2022-05-23/0/\"  # 1 ep, d=384, large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(config.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SingleDataset(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    config.max_len,\n",
    "    use_url=True  ## !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = sorted(glob.glob(EXP_FOLDER + \"*.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleTransformer(\n",
    "    config.name,\n",
    "    nb_layers=config.nb_layers,\n",
    "    no_dropout=config.no_dropout,\n",
    "    embed_dim=config.embed_dim,\n",
    "    nb_features=config.nb_features,\n",
    ").cuda()\n",
    "model.zero_grad()\n",
    "\n",
    "model = load_model_weights(model, weights[FOLD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(EXP_FOLDER + f\"fts_val_{FOLD}.npy\"):\n",
    "    preds = np.load(EXP_FOLDER + f\"fts_val_{FOLD}.npy\")\n",
    "else:\n",
    "    preds = predict(model, dataset, config.data_config)\n",
    "    np.save(EXP_FOLDER + f\"fts_val_{FOLD}.npy\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_neighbors in [200]:\n",
    "    print(f'\\n- -> n_neighbors={n_neighbors}\\n')\n",
    "\n",
    "    nn_matches = find_matches(preds, df, n_neighbors)\n",
    "    found_prop, missed_nn = compute_found_prop(nn_matches, gt_matches)\n",
    "    n_matches = sum([len(nn_matches[k]) for k in nn_matches])\n",
    "    print('NN matches :')\n",
    "    print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "    print(f'Best reachable IoU : {compute_best_iou(nn_matches, gt_matches) :.3f}\\n')\n",
    "\n",
    "#     naive_matches = json.load(open(OUT_PATH + f\"knn_preds_{n_neighbors}_0.json\", 'r'))\n",
    "    naive_matches = json.load(open(OUT_PATH + f\"dist_matches_{n_neighbors}_0.json\", 'r'))\n",
    "#     naive_matches = json.load(open(OUT_PATH + f\"dist-phone_matches_{n_neighbors}_0.json\", 'r'))\n",
    "#     naive_matches = json.load(open(OUT_PATH + f\"dist-phone-url_matches_{n_neighbors}_0.json\", 'r'))\n",
    "\n",
    "    found_prop, missed_pos = compute_found_prop(naive_matches, gt_matches)\n",
    "    n_matches = sum([len(naive_matches[k]) for k in naive_matches])\n",
    "    print('Naive matches :')\n",
    "    print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "    print(f'Best reachable IoU : {compute_best_iou(naive_matches, gt_matches) :.3f}\\n')\n",
    "\n",
    "    # UNION\n",
    "    merged_matches = {k : list(set(naive_matches[k] + nn_matches[k])) for k in nn_matches}\n",
    "    found_prop, missed = compute_found_prop(merged_matches, gt_matches)\n",
    "    n_matches = sum([len(merged_matches[k]) for k in merged_matches])\n",
    "    print('Merged matches - Union :')\n",
    "    print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "    print(f'Best reachable IoU : {compute_best_iou(merged_matches, gt_matches) :.3f}')\n",
    "    \n",
    "    df_pairs = create_pairs(nn_matches, naive_matches, n_neighbors, gt_matches)\n",
    "    prop = df_pairs['match'].sum() / len(df_pairs) * 100\n",
    "    save_path = EXP_FOLDER + f'df_pairs_{n_neighbors}.csv'\n",
    "    \n",
    "    if SAVE:\n",
    "        df_pairs.to_csv(save_path, index=False)\n",
    "        print(f'-> Saved pairs to {save_path} - Positive proportion  {prop:.2f}%\\n')\n",
    "    else:\n",
    "        print(f'Positive proportion  {prop:.2f}%\\n')\n",
    "\n",
    "    # INTERSECTION\n",
    "    merged_matches = {k : list(set(naive_matches[k]).intersection(nn_matches[k])) for k in nn_matches}\n",
    "    found_prop, missed = compute_found_prop(merged_matches, gt_matches)\n",
    "    n_matches = sum([len(merged_matches[k]) for k in merged_matches])\n",
    "    print('Merged matches - Intersection :')\n",
    "    print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "    print(f'Best reachable IoU : {compute_best_iou(merged_matches, gt_matches) :.3f}')\n",
    "    \n",
    "    df_pairs_i = df_pairs[(df_pairs['rank'] >= -0.5) &  (df_pairs['rank_nn'] >= -0.5)].reset_index(drop=True)\n",
    "    prop = df_pairs_i['match'].sum() / len(df_pairs_i) * 100\n",
    "\n",
    "    if SAVE:\n",
    "        df_pairs_i.to_csv(save_path, index=False)\n",
    "        print(f'-> Saved pairs to {save_path} - Positive proportion  {prop:.2f}%\\n')\n",
    "    else:\n",
    "        print(f'Positive proportion  {prop:.2f}%\\n')\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- -> n_neighbors=10\n",
    "\n",
    "NN matches :\n",
    "Found 65.78% of matches with 5.12M candidates.\n",
    "Best reachable IoU : 0.870\n",
    "\n",
    "Naive matches :\n",
    "Found 75.53% of matches with 5.45M candidates.\n",
    "Best reachable IoU : 0.902\n",
    "\n",
    "Merged matches :\n",
    "Found 89.25% of matches with 10.26M candidates.\n",
    "Best reachable IoU : 0.953\n",
    "\n",
    "-> Saved pairs to ../logs/2022-05-19/4/df_pairs_10.csv - Positive proportion  5.01%\n",
    "\n",
    "- -> n_neighbors=20\n",
    "\n",
    "NN matches :\n",
    "Found 70.42% of matches with 10.82M candidates.\n",
    "Best reachable IoU : 0.888\n",
    "\n",
    "Naive matches :\n",
    "Found 81.19% of matches with 10.98M candidates.\n",
    "Best reachable IoU : 0.923\n",
    "\n",
    "Merged matches :\n",
    "Found 92.87% of matches with 21.39M candidates.\n",
    "Best reachable IoU : 0.968\n",
    "\n",
    "-> Saved pairs to ../logs/2022-05-19/4/df_pairs_20.csv - Positive proportion  2.81%\n",
    "\n",
    "- -> n_neighbors=30\n",
    "\n",
    "NN matches :\n",
    "Found 72.90% of matches with 16.51M candidates.\n",
    "Best reachable IoU : 0.897\n",
    "\n",
    "Naive matches :\n",
    "Found 83.91% of matches with 16.42M candidates.\n",
    "Best reachable IoU : 0.933\n",
    "\n",
    "Merged matches :\n",
    "Found 94.42% of matches with 32.45M candidates.\n",
    "Best reachable IoU : 0.974\n",
    "\n",
    "-> Saved pairs to ../logs/2022-05-19/4/df_pairs_30.csv - Positive proportion  2.01%\n",
    "\n",
    "- -> n_neighbors=40\n",
    "\n",
    "NN matches :\n",
    "Found 74.59% of matches with 22.21M candidates.\n",
    "Best reachable IoU : 0.903\n",
    "\n",
    "Naive matches :\n",
    "Found 85.59% of matches with 21.77M candidates.\n",
    "Best reachable IoU : 0.940\n",
    "\n",
    "Merged matches :\n",
    "Found 95.32% of matches with 43.44M candidates.\n",
    "Best reachable IoU : 0.978\n",
    "\n",
    "-> Saved pairs to ../logs/2022-05-19/4/df_pairs_40.csv - Positive proportion  1.58%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 100):\n",
    "#     print(i)\n",
    "    idx = df.index[i]\n",
    "\n",
    "    if len(gt_matches[idx]) <= 1:\n",
    "        continue\n",
    "        \n",
    "    if len(gt_matches[idx]) > 10:\n",
    "        continue\n",
    "\n",
    "    found = [idx] + list(set(merged_matches[idx]).intersection(set(gt_matches[idx])))\n",
    "    all_found = sorted(found) == sorted(gt_matches[idx])\n",
    "\n",
    "    if all_found:\n",
    "        continue\n",
    "    \n",
    "#     if merged_matches[k]\n",
    "    found_naive = [idx] + list(set(naive_matches[idx]).intersection(set(gt_matches[idx])))\n",
    "    all_found_naive = sorted(found_naive) == sorted(gt_matches[idx])\n",
    "    \n",
    "    if all_found:\n",
    "        continue\n",
    "\n",
    "    print('Query')\n",
    "    display(df.loc[[idx]])\n",
    "\n",
    "    print('Target')\n",
    "    display(df.loc[gt_matches[idx]])\n",
    "\n",
    "    print('Found naive')\n",
    "    display(df.loc[list(found_naive)])\n",
    "    \n",
    "    print('Found NN')\n",
    "    found_nn = [idx] + list(set(nn_matches[idx]).intersection(set(gt_matches[idx])))\n",
    "    display(df.loc[list(found_nn)])\n",
    "    \n",
    "    display(df.loc[nn_matches[idx]])\n",
    "\n",
    "    break\n",
    "    print('-' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
