{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to match candidates naively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import cudf\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "from numerize.numerize import numerize\n",
    "\n",
    "pandarallel.initialize(progress_bar=False, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.metrics import *\n",
    "from inference.knn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = cudf.read_csv(DATA_PATH + \"df_train.csv\").set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = cudf.read_csv(DATA_PATH + f\"folds_{K}.csv\")[['id', 'fold']]\n",
    "\n",
    "df = df.merge(folds, how=\"left\", on=\"id\").set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_matches = json.load(open(DATA_PATH + \"gt.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_IDX = 0\n",
    "df_val = df[df['fold'] == FOLD_IDX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['country_reverse'] = [c['country_code'] for c in reverse_geocode.search(df[['latitude', 'longitude']].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_diff = df[df['country_reverse'] != df['country']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_diff['country_reverse_swap'] = [\n",
    "#     c['country_code'] for c in reverse_geocode.search(df_diff[['longitude', 'latitude']].values)\n",
    "# ]\n",
    "\n",
    "# df_diff['country_reverse_swap'] = [\n",
    "#     c['country_code'] for c in reverse_geocode.search(df_diff[['longitude', 'latitude']].values)\n",
    "# ]\n",
    "# df_diff['city_reverse_swap'] = [\n",
    "#     c['city'] for c in reverse_geocode.search(df_diff[['longitude', 'latitude']].values)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# len(df_diff[df_diff['country_reverse_swap'] == df_diff['country']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country = \"BR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc = df[df['country'] == country].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reverse_geocode\n",
    "\n",
    "# countries = [c['country_code'] for c in reverse_geocode.search(dfc[['latitude', 'longitude']].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc['country_reverse'] = countries\n",
    "\n",
    "# dfc_w = dfc[dfc['country_reverse'] != country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dfc_w['country_reverse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# len(dfc_w)\n",
    "\n",
    "# countries_r = [c['country_code'] for c in reverse_geocode.search(dfc_w[['longitude', 'latitude']].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.scatter(dfc['longitude'], dfc['latitude'], s=1)\n",
    "\n",
    "# plt.scatter(dfc_w['longitude'], dfc_w['latitude'], s=1)\n",
    "\n",
    "# # plt.scatter(dfc_w['latitude'], dfc_w['longitude'], s=50)\n",
    "# # plt.scatter(-dfc_w['longitude'], dfc_w['latitude'], s=50)\n",
    "# # plt.scatter(dfc_w['longitude'], -dfc_w['latitude'], s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_DIST = None\n",
    "MAX_DIST = 0.5\n",
    "NEIGHBORS =  [50, 100]\n",
    "\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_neighbors in NEIGHBORS:\n",
    "    print(f'\\n -> n_neighbors={n_neighbors} - max_dist={MAX_DIST}\\n')\n",
    "\n",
    "    dist_matches = get_nearest_neighbors(df_val, n_neighbors=n_neighbors, max_dist=MAX_DIST)\n",
    "#     dist_matches = get_nearest_neighbors_country(df_val.to_pandas(), n_neighbors=n_neighbors, max_dist=MAX_DIST)\n",
    "\n",
    "    found_prop, missed = compute_found_prop(dist_matches, gt_matches)\n",
    "    n_matches = sum([len(dist_matches[k]) for k in dist_matches])\n",
    "\n",
    "    print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "    print(f'Best reachable IoU : {compute_best_iou(dist_matches, gt_matches) :.3f}')\n",
    "\n",
    "    if SAVE:\n",
    "        with open(OUT_PATH + f\"dist_matches_{n_neighbors}_{FOLD_IDX}.json\", \"w\") as f:\n",
    "            json.dump(dist_matches, f)\n",
    "            print(\"\\n- Saved to \", OUT_PATH + f\"dist_matches_{n_neighbors}_{FOLD_IDX}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +Swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for max_dist in [None]:\n",
    "#     for n_neighbors in NEIGHBORS:\n",
    "#         print(f'\\n -> n_neighbors={n_neighbors} - max_dist={max_dist}\\n')\n",
    "\n",
    "#         dist_matches = get_nearest_neighbors_swapped(df_val, n_neighbors=n_neighbors, max_dist=max_dist)\n",
    "\n",
    "#         found_prop, missed = compute_found_prop(dist_matches, gt_matches)\n",
    "#         n_matches = sum([len(dist_matches[k]) for k in dist_matches])\n",
    "\n",
    "#         print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "#         print(f'Best reachable IoU : {compute_best_iou(dist_matches, gt_matches) :.3f}')\n",
    "\n",
    "# #         with open(OUT_PATH + f\"dist_matches_{n_neighbors}_{FOLD_IDX}.json\", \"w\") as f:\n",
    "# #             json.dump(dist_matches, f)\n",
    "# #             print(\"\\n- Saved to \", OUT_PATH + f\"dist_matches_{n_neighbors}_{FOLD_IDX}.json\")\n",
    "\n",
    "# #         break\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_neighbors = 100\n",
    "# max_dist = 0.5\n",
    "# lim = 20  # ??\n",
    "\n",
    "# all_fps = {}\n",
    "# for fold_idx in tqdm(range(K)):\n",
    "#     df_val = df[df['fold'] == fold_idx]\n",
    "#     dist_matches = get_nearest_neighbors(df_val, n_neighbors=n_neighbors)\n",
    "#     fps = {id_ : \" \".join(list(set(dist_matches[id_]) - set(gt_matches[id_]))[:lim]) for id_ in dist_matches}\n",
    "#     all_fps.update(fps)  # TODO : update ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_fps = pd.DataFrame.from_dict(all_fps, orient=\"index\").reset_index()\n",
    "# df_fps.columns = [\"id\", 'fp_ids']\n",
    "\n",
    "# triplets = prepare_triplet_data(root=DATA_PATH)\n",
    "# triplets.drop('fp_ids', axis=1, inplace=True)\n",
    "\n",
    "# triplets = triplets.merge(df_fps, how=\"left\")\n",
    "# triplets.to_csv(DATA_PATH + 'triplets_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phone number\n",
    "- Count encoding for phone numbers present too many times ?\n",
    "- Phone found twice = match ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from inference.knn import find_phone_matches, find_url_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['phone_len'] = df_val[['phone']].to_pandas()['phone'].fillna('').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(x=df_val['phone_len'].values.get())\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_phone = df_val[df_val['phone_len'] > 5]\n",
    "df_phone = df_phone[df_phone['phone_len'] < 25]\n",
    "\n",
    "df_phone = df_phone.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_matches = {}\n",
    "\n",
    "for country, df_phone_c in tqdm(df_phone.groupby(\"country\")):\n",
    "#     print(country, len(df_phone_c))\n",
    "    if country == \"US\":\n",
    "        # Group by state\n",
    "        for state, df_phone_c_s in tqdm(df_phone_c.groupby(\"state\")):\n",
    "            for id_ in df_phone_c_s.index:\n",
    "                m = find_phone_matches(id_, df_phone_c_s)\n",
    "                if len(m):\n",
    "                    phone_matches[id_] = m\n",
    "    else:\n",
    "        for id_ in df_phone_c.index:\n",
    "            m = find_phone_matches(id_, df_phone_c)\n",
    "            if len(m):\n",
    "                phone_matches[id_] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    k = list(phone_matches.keys())[i]\n",
    "    k = np.random.choice(list(phone_matches.keys()))\n",
    "    display(df.loc[[k] + phone_matches[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_neighbors in NEIGHBORS:\n",
    "    print(f'\\n -> n_neighbors={n_neighbors}\\n')\n",
    "\n",
    "    position_matches = json.load(open(OUT_PATH + f\"dist_matches_{n_neighbors}_0.json\", 'r'))\n",
    "    found_prop, missed_pos = compute_found_prop(position_matches, gt_matches)\n",
    "    n_matches = sum([len(position_matches[k]) for k in position_matches])\n",
    "    print(f'Position :\\t Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "\n",
    "    merged_matches = {\n",
    "        k : matches + [m for m in phone_matches.get(k, []) if m not in matches] for k, matches in position_matches.items()\n",
    "    }\n",
    "    found_prop, missed = compute_found_prop(merged_matches, gt_matches)\n",
    "    n_matches = sum([len(merged_matches[k]) for k in merged_matches])\n",
    "    print(f'Merged :\\t found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_url_len = 25  # 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['url_len'] = df_val[['url']].to_pandas()['url'].fillna('').apply(len)\n",
    "\n",
    "df_url = df_val[df_val['url_len'] > min_url_len].to_pandas()\n",
    "\n",
    "len(df_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.histplot(x=df_url['url_len'], bins=100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_matches = {}\n",
    "\n",
    "for country, df_url_c in tqdm(df_url.groupby(\"country\")):\n",
    "    if country == \"US\":\n",
    "        # Group by state\n",
    "        for state, df_url_c_s in tqdm(df_url_c.groupby(\"state\")):\n",
    "            for id_ in df_url_c_s.index:\n",
    "                m = find_url_matches(id_, df_url_c_s)\n",
    "                if len(m):\n",
    "                    url_matches[id_] = m\n",
    "    else:\n",
    "        for id_ in df_url_c.index:\n",
    "            m = find_url_matches(id_, df_url_c)\n",
    "            if len(m):\n",
    "                url_matches[id_] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    k = list(url_matches.keys())[i]\n",
    "    k = np.random.choice(list(url_matches.keys()))\n",
    "    display(df.loc[[k] + url_matches[k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final results & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_neighbors in NEIGHBORS:\n",
    "    print(f'\\n -> n_neighbors={n_neighbors}\\n')\n",
    "\n",
    "    # Pos\n",
    "    position_matches = json.load(open(OUT_PATH + f\"dist_matches_{n_neighbors}_0.json\", 'r'))\n",
    "    found_prop, missed_pos = compute_found_prop(position_matches, gt_matches)\n",
    "    n_matches = sum([len(position_matches[k]) for k in position_matches])\n",
    "    print(\"Position :\")\n",
    "    print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "    print(f'Best reachable IoU : {compute_best_iou(position_matches, gt_matches) :.3f}\\n')\n",
    "\n",
    "    # Pos + Phone\n",
    "    merged_matches = {\n",
    "        k : matches + [m for m in phone_matches.get(k, []) if m not in matches]\n",
    "        for k, matches in position_matches.items()\n",
    "    }\n",
    "    found_prop, missed = compute_found_prop(merged_matches, gt_matches)\n",
    "    n_matches = sum([len(merged_matches[k]) for k in merged_matches])\n",
    "    print(\"Position + Phone:\")\n",
    "    print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "    print(f'Best reachable IoU : {compute_best_iou(merged_matches, gt_matches) :.3f}\\n')\n",
    "\n",
    "    if SAVE:\n",
    "        with open(OUT_PATH + f\"dist-phone_matches_{n_neighbors}_{FOLD_IDX}.json\", \"w\") as f:\n",
    "            json.dump(merged_matches, f)\n",
    "#         print(\"\\n- Saved to \", OUT_PATH + f\"dist-phone_matches_{n_neighbors}_{FOLD_IDX}.json\\n\")\n",
    "\n",
    "    # Pos + Phone + Url\n",
    "    merged_matches = {\n",
    "        k : matches + [m for m in url_matches.get(k, []) if m not in matches]\n",
    "        for k, matches in merged_matches.items()\n",
    "    }\n",
    "\n",
    "    found_prop, missed = compute_found_prop(merged_matches, gt_matches)\n",
    "    n_matches = sum([len(merged_matches[k]) for k in merged_matches])\n",
    "\n",
    "    print(\"Position + Phone + Url:\")\n",
    "    print(f'Found {found_prop * 100 :.2f}% of matches with {numerize(n_matches)} candidates.')\n",
    "    print(f'Best reachable IoU : {compute_best_iou(merged_matches, gt_matches) :.3f}\\n')\n",
    "\n",
    "    if SAVE:\n",
    "        with open(OUT_PATH + f\"dist-phone-url_matches_{n_neighbors}_{FOLD_IDX}.json\", \"w\") as f:\n",
    "            json.dump(merged_matches, f)\n",
    "#         print(\"\\n- Saved to \", OUT_PATH + f\"dist-phone-url_matches_{n_neighbors}_{FOLD_IDX}.json\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
